# -*- coding: utf-8 -*-
"""Codigo_base_Tarea_2_IA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oY-RE6eW8nLf8jr9uzIGWqRi5B0bWULy

# Universidad de O'Higgins

## Escuela de Ingeniería
## COM4402: Introducción a Inteligencia Artificial

### **Tarea 2: Clasificación de Dígitos Manuscritos con Redes Neuronales**

### Estudiante: Francisco Ignacio Guzmán Ramírez

El objetivo de esta tarea es utilizar redes neuronales en un problema de clasificación de dígitos. Se utilizará el conjunto de datos Optical Recognition of Handwritten Digits Data Set. Este conjunto tiene 64 características, con 10 clases y 5620 muestras en total. La base de datos estará disponible en U-Campus.

Las redes a ser entrenadas tienen la siguiente estructura: capa de entrada de dimensionalidad 64 (correspondiente a los datos de entrada), capas ocultas (una o dos) y capa de salida con 10 neuronas y función de activación softmax. La función de loss (pérdida) es entropía cruzada. El optimizador que se
debe usar es Adam. La función softmax está implícita al usar la función de pérdida CrossEntropyLoss de PyTorch (**no se debe agregar softmax a la salida de la red**).

Se usará PyTorch para entrenar y validar la red neuronal que implementa el clasificador de dígitos. Se analizará los efectos de cambiar el tamaño de la red (número de capas ocultas y de neuronas en estas
capas) y la función de activación.

El siguiente código base debe ser usado para realizar las actividades pedidas.

## Observación: Antes de ejecutar su código, active el uso de GPU en Google Colab para acelerar el proceso de entrenamiento.

### Para esto: vaya a "Entorno de Ejecución" en el menú superior, haga click en "Cambiar tipo de entorno de ejecución", y seleccionar/verificar "GPU" en "Acelerador de Hardware"
"""

import pandas as pd
import torch
import torch.nn as nn
import numpy as np
import time
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix,accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

!wget https://raw.githubusercontent.com/Felipe1401/Mineria/main/dataset_digits/1_digits_train.txt

!wget https://raw.githubusercontent.com/Felipe1401/Mineria/main/dataset_digits/1_digits_test.txt

"""## Subir datasets de dígitos (train)

## Leer dataset de dígitos
"""

column_names = ["feat" + str(i) for i in range(64)]
column_names.append("class")

df_train_val = pd.read_csv('1_digits_train.txt', names = column_names)
df_train_val

df_test = pd.read_csv('1_digits_test.txt', names = column_names)
df_test

"""**Se dividen los datos de entrenamiento en validación, entrenamiento y prueba.**"""

df_train, df_val = train_test_split(df_train_val, test_size = 0.3, random_state = 10)

scaler = StandardScaler().fit(df_train.iloc[:,0:64])
df_train.iloc[:,0:64] = scaler.transform(df_train.iloc[:,0:64])
df_val.iloc[:,0:64] = scaler.transform(df_val.iloc[:,0:64])
df_test.iloc[:,0:64] = scaler.transform(df_test.iloc[:,0:64])

df_train

"""## Se Crean datasets y dataloaders para pytorch (train)"""

# Crear datasets
feats_train = df_train.to_numpy()[:,0:64].astype(np.float32)
labels_train = df_train.to_numpy()[:,64].astype(int)
dataset_train = [ {"features":feats_train[i,:], "labels":labels_train[i]} for i in range(feats_train.shape[0]) ]

feats_val = df_val.to_numpy()[:,0:64].astype(np.float32)
labels_val = df_val.to_numpy()[:,64].astype(int)
dataset_val = [ {"features":feats_val[i,:], "labels":labels_val[i]} for i in range(feats_val.shape[0]) ]

feats_test = df_test.to_numpy()[:,0:64].astype(np.float32)
labels_test = df_test.to_numpy()[:,64].astype(int)
dataset_test = [ {"features":feats_test[i,:], "labels":labels_test[i]} for i in range(feats_test.shape[0]) ]

# Crear dataloaders
dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=128, shuffle=True, num_workers=0)
dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=128, shuffle=True, num_workers=0)
dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=128, shuffle=True, num_workers=0)

"""## Se crea un modelo para cada caso

**(a) 10 neuronas en la capa oculta, usando función de activación ReLU y 1000 épocas como máximo**
"""

model1 = nn.Sequential(
          nn.Linear(64, 10),
          nn.ReLU(),
          nn.Linear(10,10)
        )

device = torch.device('cuda')

model1 = model1.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model1.parameters(), lr=1e-3)

"""## Entrenamiento"""

start = time.time()
last = []
loss_train= []
loss_val= []
accuracy_t = [] #guarda accuracy en cada batch, en el entrenamiento
accuracy_v = []
epocas = []
cont = 0
paciencia = 7
truelabels = []
prediclabels = []
# loop over the dataset multiple times
for epoch in range(1000):
  # Guardar loss de cada batch
  loss_train_batches = [] # guarda pérdidas de cada batch en el entrenamiento
  loss_val_batches = []
  model1.train()
  correct = 0
  total = 0
  total1 = 0
  correct1 = 0

  # Train on the current epoch
  for i, data in enumerate(dataloader_train, 0):
    # Process the current batch
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    # zero the parameter gradients
    optimizer.zero_grad()
    # forward + backward + optimize
    outputs = model1(inputs)
    loss = criterion(outputs, labels)
    loss.backward() # backpropagation
    optimizer.step()

    # Por completar: calcule la pérdida de entrenamiento y acurracy en el batch actual
    loss_train_batches.append(loss.item())

##-----------Accuracy en la época actual--------------------------------------
    _, predicted = torch.max(outputs, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
  accuracy = correct / total
  accuracy_t.append(accuracy)
  ##-----------------------------------------------------------------------------------------

  # Pérdida de entrenamiento y accuracy en la época actual
  loss_train.append(np.mean(loss_train_batches)) #***loss promedio en cada época***

###--------------------***Predicción en el conjunto de validación***------------------
  model1.eval()


  with torch.no_grad():
    # Por completar: calcule la pérdida de validación y acurracy en la época actual
    for i, data in enumerate(dataloader_val, 0):
      # Procesar batch actual
      inputs = data["features"].to(device) # Características
      labels = data["labels"].to(device)   # Clases

      outputs = model1(inputs)              # Obtenemos predicciones

      # Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      loss_val_batches.append(loss.item())
##-----------Accuracy en la época actual--------------------------------------
      _, predicted = torch.max(outputs, 1)
      total1 += labels.size(0)
      correct1 += (predicted == labels).sum().item()
  accuracy = correct1 / total1
  accuracy_v.append(accuracy)
##-------------------------------------------------------------------------------------------

  # Guardamos el Loss de validación de la época actual
  loss_val.append(np.mean(loss_val_batches)) # Loss promedio de los batches
  epocas.append(epoch)
  # Código para evitar el sobreajuste, según el valor de paciencia ----------------------------
  if len(loss_val)>1:
    dif=loss_val[-1]-loss_val[-2]
    if dif >= 0:
      cont+=1
      if cont >= paciencia:
        break


  # Por hacer: imprima la pérdida de entrenamiento/validación y acurracy en la época actual
  print('epoch: %d, mean train loss: %.4f, mean val loss: %.4f, accuracy train: %.4f, accuracy val: %f' %((epoch), loss_train[epoch], loss_val[epoch], accuracy_t[epoch], accuracy_v[epoch] ))


# Crea un mapa de calor de la matriz de confusión-------------------------------------------
last.append(accuracy_v[epoch-1])
end = time.time()

print('Finished Training, total time %f seconds' % (end - start))
print(accuracy_v)

#----------------Matriz de confusión---------------------------
model1.eval()
with torch.no_grad():
  for i, data in enumerate(dataloader_train, 0):
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    outputs = model1(inputs)
    _, predicted = torch.max(outputs, 1)
    truelabels.extend(labels.cpu().numpy())
    prediclabels.extend(predicted.cpu().numpy())
cm = confusion_matrix(truelabels, prediclabels, normalize='true')
accuracy=accuracy_score(truelabels, prediclabels)
class_labels = ["Clase 0", "Clase 1", "Clase 1", "Clase 2", "Clase 3", "Clase 4", "Clase 5", "Clase 6", "Clase 7", "Clase 8", "Clase 9"]
plt.figure(figsize=(8, 6))
accutxt=f'accuracy: {accuracy*100:.2f}%,'
sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicción')
plt.ylabel('Etiqueta Real')
plt.title('Matriz de Confusión '+ accutxt)
plt.show()
with torch.no_grad():
  for i, data in enumerate(dataloader_val, 0):
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    outputs = model1(inputs)
    _, predicted = torch.max(outputs, 1)
    truelabels.extend(labels.cpu().numpy())
    prediclabels.extend(predicted.cpu().numpy())
cm = confusion_matrix(truelabels, prediclabels, normalize='true')
accuracy=accuracy_score(truelabels, prediclabels)
class_labels = ["Clase 0", "Clase 1", "Clase 1", "Clase 2", "Clase 3", "Clase 4", "Clase 5", "Clase 6", "Clase 7", "Clase 8", "Clase 9"]
plt.figure(figsize=(8, 6))
accutxt=f'accuracy: {accuracy*100:.2f}%,'
sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicción')
plt.ylabel('Etiqueta Real')
plt.title('Matriz de Confusión '+ accutxt)
plt.show()

# Graficar loss de entrenamiento Y validación
plt.figure(figsize = (8, 5))
plt.title('pérdida en entrenamiento y validación')
plt.xlabel('Épocas')
plt.ylabel('Pérdida')
plt.plot(epocas, loss_train, 'b', label = 'Entrenamiento')
plt.plot(epocas, loss_val, 'r', label = 'Validación')
plt.grid()
plt.legend()

"""**(b) 40 neuronas en la capa oculta y función de activación ReLU, y 1000 épocas como máximo.**"""

model2 = nn.Sequential(
          nn.Linear(64, 40),
          nn.ReLU(),
          nn.Linear(40,10)
        )

device = torch.device('cuda')

model2 = model2.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model2.parameters(), lr=1e-3)

start = time.time()

loss_train= []
loss_val= []
accuracy_t = [] #guarda accuracy en cada batch, en el entrenamiento
accuracy_v = []
epocas = []
cont = 0
paciencia = 8
truelabels = []
prediclabels = []
# loop over the dataset multiple times
for epoch in range(1000):
  # Guardar loss de cada batch
  loss_train_batches = [] # guarda pérdidas de cada batch en el entrenamiento
  loss_val_batches = []
  model2.train()
  correct = 0
  total = 0
  total1 = 0
  correct1 = 0

  # Train on the current epoch
  for i, data in enumerate(dataloader_train, 0):
    # Process the current batch
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    # zero the parameter gradients
    optimizer.zero_grad()
    # forward + backward + optimize
    outputs = model2(inputs)
    loss = criterion(outputs, labels)
    loss.backward() # backpropagation
    optimizer.step()

    # Por completar: calcule la pérdida de entrenamiento y acurracy en el batch actual
    loss_train_batches.append(loss.item())

##-----------Accuracy en la época actual--------------------------------------
    _, predicted = torch.max(outputs, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
  accuracy = correct / total
  accuracy_t.append(accuracy)
  ##-----------------------------------------------------------------------------------------

  # Pérdida de entrenamiento y accuracy en la época actual
  loss_train.append(np.mean(loss_train_batches)) #***loss promedio en cada época***


###--------------------***Predicción en el conjunto de validación***------------------
  model2.eval()
  with torch.no_grad():
    # Por completar: calcule la pérdida de validación y acurracy en la época actual
    for i, data in enumerate(dataloader_val, 0):
      # Procesar batch actual
      inputs = data["features"].to(device) # Características
      labels = data["labels"].to(device)   # Clases

      outputs = model2(inputs)              # Obtenemos predicciones

      # Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      loss_val_batches.append(loss.item())
##-----------Accuracy en la época actual--------------------------------------
      _, predicted = torch.max(outputs, 1)
      total1 += labels.size(0)
      correct1 += (predicted == labels).sum().item()
  accuracy = correct1 / total1
  accuracy_v.append(accuracy)
##-------------------------------------------------------------------------------------------

  # Guardamos el Loss de validación de la época actual
  loss_val.append(np.mean(loss_val_batches)) # Loss promedio de los batches
  epocas.append(epoch)
  if len(loss_val)>1:
    dif=loss_val[-1]-loss_val[-2]
    if dif >= 0:
      cont+=1
      if cont >= paciencia:
        break


  # Por hacer: imprima la pérdida de entrenamiento/validación y acurracy en la época actual
  print('epoch: %d, mean train loss: %.4f, mean val loss: %.4f, accuracy train: %.4f, accuracy val: %.4f' %((epoch), loss_train[epoch], loss_val[epoch], accuracy_t[epoch], accuracy_v[epoch] ))


# Crea un mapa de calor de la matriz de confusión-------------------------------------------
last.append(accuracy_v[epoch-1])
end = time.time()

print('Finished Training, total time %f seconds' % (end - start))

#----------------Matriz de confusión---------------------------
model2.eval()
with torch.no_grad():
  for i, data in enumerate(dataloader_train, 0):
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    outputs = model2(inputs)
    _, predicted = torch.max(outputs, 1)
    truelabels.extend(labels.cpu().numpy())
    prediclabels.extend(predicted.cpu().numpy())
cm = confusion_matrix(truelabels, prediclabels, normalize='true')
accuracy=accuracy_score(truelabels, prediclabels)
class_labels = ["Clase 0", "Clase 1", "Clase 1", "Clase 2", "Clase 3", "Clase 4", "Clase 5", "Clase 6", "Clase 7", "Clase 8", "Clase 9"]
plt.figure(figsize=(8, 6))
accutxt=f'accuracy: {accuracy*100:.2f}%,'
sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicción')
plt.ylabel('Etiqueta Real')
plt.title('Matriz de Confusión '+ accutxt)
plt.show()
with torch.no_grad():
  for i, data in enumerate(dataloader_val, 0):
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    outputs = model2(inputs)
    _, predicted = torch.max(outputs, 1)
    truelabels.extend(labels.cpu().numpy())
    prediclabels.extend(predicted.cpu().numpy())
cm = confusion_matrix(truelabels, prediclabels, normalize='true')
accuracy=accuracy_score(truelabels, prediclabels)
class_labels = ["Clase 0", "Clase 1", "Clase 1", "Clase 2", "Clase 3", "Clase 4", "Clase 5", "Clase 6", "Clase 7", "Clase 8", "Clase 9"]
plt.figure(figsize=(8, 6))
accutxt=f'accuracy: {accuracy*100:.2f}%,'
sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicción')
plt.ylabel('Etiqueta Real')
plt.title('Matriz de Confusión '+ accutxt)
plt.show()

# Graficar loss de entrenamiento Y validación-----------------------------
plt.figure(figsize = (8, 5))
plt.title('pérdida en entrenamiento y validación')
plt.xlabel('Épocas')
plt.ylabel('Pérdida')
plt.plot(epocas, loss_train, 'b', label = 'Entrenamiento')
plt.plot(epocas, loss_val, 'r', label = 'Validación')
plt.grid()
plt.legend()

"""(c) 10 neuronas en la capa oculta y función de activación Tanh, y 1000 épocas como máximo"""

model3 = nn.Sequential(
          nn.Linear(64, 10),
          nn.Tanh(),
          nn.Linear(10,10)
        )

device = torch.device('cuda')

model3 = model3.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model3.parameters(), lr=1e-3)

start = time.time()

loss_train= []
loss_val= []
accuracy_t = [] #guarda accuracy en cada batch, en el entrenamiento
accuracy_v = []
epocas = []
cont = 0
paciencia = 9
truelabels = []
prediclabels = []
# loop over the dataset multiple times
for epoch in range(1000):
  # Guardar loss de cada batch
  loss_train_batches = [] # guarda pérdidas de cada batch en el entrenamiento
  loss_val_batches = []
  model3.train()
  correct = 0
  total = 0
  total1 = 0
  correct1 = 0

  # Train on the current epoch
  for i, data in enumerate(dataloader_train, 0):
    # Process the current batch
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    # zero the parameter gradients
    optimizer.zero_grad()
    # forward + backward + optimize
    outputs = model3(inputs)
    loss = criterion(outputs, labels)
    loss.backward() # backpropagation
    optimizer.step()

    # Por completar: calcule la pérdida de entrenamiento y acurracy en el batch actual
    loss_train_batches.append(loss.item())

##-----------Accuracy en la época actual--------------------------------------
    _, predicted = torch.max(outputs, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
  accuracy = correct / total
  accuracy_t.append(accuracy)
  ##-----------------------------------------------------------------------------------------

  # Pérdida de entrenamiento y accuracy en la época actual
  loss_train.append(np.mean(loss_train_batches)) #***loss promedio en cada época***

###--------------------***Predicción en el conjunto de validación***------------------
  model3.eval()


  with torch.no_grad():
    # Por completar: calcule la pérdida de validación y acurracy en la época actual
    for i, data in enumerate(dataloader_val, 0):
      # Procesar batch actual
      inputs = data["features"].to(device) # Características
      labels = data["labels"].to(device)   # Clases

      outputs = model3(inputs)              # Obtenemos predicciones

      # Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      loss_val_batches.append(loss.item())
##-----------Accuracy en la época actual--------------------------------------
      _, predicted = torch.max(outputs, 1)
      total1 += labels.size(0)
      correct1 += (predicted == labels).sum().item()
  accuracy = correct1 / total1
  accuracy_v.append(accuracy)
##-------------------------------------------------------------------------------------------

  # Guardamos el Loss de validación de la época actual
  loss_val.append(np.mean(loss_val_batches)) # Loss promedio de los batches
  epocas.append(epoch)
  if len(loss_val)>1:
    dif=loss_val[-1]-loss_val[-2]
    if dif >= 0:
      cont+=1
      if cont >= paciencia:
        break


  # Por hacer: imprima la pérdida de entrenamiento/validación y acurracy en la época actual
  print('epoch: %d, mean train loss: %.4f, mean val loss: %.4f, accuracy train: %.4f, accuracy val: %.4f' %((epoch), loss_train[epoch], loss_val[epoch], accuracy_t[epoch], accuracy_v[epoch] ))


# Crea un mapa de calor de la matriz de confusión-------------------------------------------
last.append(accuracy_v[epoch-1])
end = time.time()

print('Finished Training, total time %f seconds' % (end - start))

#----------------Matriz de confusión---------------------------
model3.eval()
with torch.no_grad():
  for i, data in enumerate(dataloader_train, 0):
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    outputs = model3(inputs)
    _, predicted = torch.max(outputs, 1)
    truelabels.extend(labels.cpu().numpy())
    prediclabels.extend(predicted.cpu().numpy())
cm = confusion_matrix(truelabels, prediclabels, normalize='true')
accuracy=accuracy_score(truelabels, prediclabels)
class_labels = ["Clase 0", "Clase 1", "Clase 1", "Clase 2", "Clase 3", "Clase 4", "Clase 5", "Clase 6", "Clase 7", "Clase 8", "Clase 9"]
plt.figure(figsize=(8, 6))
accutxt=f'accuracy: {accuracy*100:.2f}%,'
sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicción')
plt.ylabel('Etiqueta Real')
plt.title('Matriz de Confusión '+ accutxt)
plt.show()
with torch.no_grad():
  for i, data in enumerate(dataloader_val, 0):
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    outputs = model3(inputs)
    _, predicted = torch.max(outputs, 1)
    truelabels.extend(labels.cpu().numpy())
    prediclabels.extend(predicted.cpu().numpy())
cm = confusion_matrix(truelabels, prediclabels, normalize='true')
accuracy=accuracy_score(truelabels, prediclabels)
class_labels = ["Clase 0", "Clase 1", "Clase 1", "Clase 2", "Clase 3", "Clase 4", "Clase 5", "Clase 6", "Clase 7", "Clase 8", "Clase 9"]
plt.figure(figsize=(8, 6))
accutxt=f'accuracy: {accuracy*100:.2f}%,'
sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicción')
plt.ylabel('Etiqueta Real')
plt.title('Matriz de Confusión '+ accutxt)
plt.show()

# Graficar loss de entrenamiento Y validación
plt.figure(figsize = (8, 5))
plt.title('pérdida en entrenamiento y validación')
plt.xlabel('Épocas')
plt.ylabel('Pérdida')
plt.plot(epocas, loss_train, 'b', label = 'Entrenamiento')
plt.plot(epocas, loss_val, 'r', label = 'Validación')
plt.grid()
plt.legend()

"""(d) 40 neuronas en la capa oculta y función de activación Tanh, y 1000 épocas como máximo."""

model4 = nn.Sequential(
          nn.Linear(64, 40),
          nn.Tanh(),
          nn.Linear(40,10)
        )

device = torch.device('cuda')

model4 = model4.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model4.parameters(), lr=1e-3)

start = time.time()

loss_train= []
loss_val= []
accuracy_t = [] #guarda accuracy en cada batch, en el entrenamiento
accuracy_v = []
epocas = []
cont = 0
paciencia =6
truelabels = []
prediclabels = []
# loop over the dataset multiple times
for epoch in range(1000):
  # Guardar loss de cada batch
  loss_train_batches = [] # guarda pérdidas de cada batch en el entrenamiento
  loss_val_batches = []
  model4.train()
  correct = 0
  total = 0
  total1 = 0
  correct1 = 0

  # Train on the current epoch
  for i, data in enumerate(dataloader_train, 0):
    # Process the current batch
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    # zero the parameter gradients
    optimizer.zero_grad()
    # forward + backward + optimize
    outputs = model4(inputs)
    loss = criterion(outputs, labels)
    loss.backward() # backpropagation
    optimizer.step()

    # Por completar: calcule la pérdida de entrenamiento y acurracy en el batch actual
    loss_train_batches.append(loss.item())

##-----------Accuracy en la época actual--------------------------------------
    _, predicted = torch.max(outputs, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
  accuracy = correct / total
  accuracy_t.append(accuracy)
  ##-----------------------------------------------------------------------------------------

  # Pérdida de entrenamiento y accuracy en la época actual
  loss_train.append(np.mean(loss_train_batches)) #***loss promedio en cada época***

###--------------------***Predicción en el conjunto de validación***------------------
  model4.eval()


  with torch.no_grad():
    # Por completar: calcule la pérdida de validación y acurracy en la época actual
    for i, data in enumerate(dataloader_val, 0):
      # Procesar batch actual
      inputs = data["features"].to(device) # Características
      labels = data["labels"].to(device)   # Clases

      outputs = model4(inputs)              # Obtenemos predicciones

      # Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      loss_val_batches.append(loss.item())
##-----------Accuracy en la época actual--------------------------------------
      _, predicted = torch.max(outputs, 1)
      total1 += labels.size(0)
      correct1 += (predicted == labels).sum().item()
  accuracy = correct1 / total1
  accuracy_v.append(accuracy)
##-------------------------------------------------------------------------------------------

  # Guardamos el Loss de validación de la época actual
  loss_val.append(np.mean(loss_val_batches)) # Loss promedio de los batches
  epocas.append(epoch)
  if len(loss_val)>1:
    dif=loss_val[-1]-loss_val[-2]
    if dif >= 0:
      cont+=1
      if cont >= paciencia:
        break


  # Por hacer: imprima la pérdida de entrenamiento/validación y acurracy en la época actual
  print('epoch: %d, mean train loss: %.4f, mean val loss: %.4f, accuracy train: %.4f, accuracy val: %f' %((epoch), loss_train[epoch], loss_val[epoch], accuracy_t[epoch], accuracy_v[epoch] ))


# Crea un mapa de calor de la matriz de confusión-------------------------------------------
last.append(accuracy_v[epoch-1])
end = time.time()

print('Finished Training, total time %f seconds' % (end - start))

#----------------Matriz de confusión---------------------------
model4.eval()
with torch.no_grad():
  for i, data in enumerate(dataloader_train, 0):
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    outputs = model4(inputs)
    _, predicted = torch.max(outputs, 1)
    truelabels.extend(labels.cpu().numpy())
    prediclabels.extend(predicted.cpu().numpy())
cm = confusion_matrix(truelabels, prediclabels, normalize='true')
accuracy=accuracy_score(truelabels, prediclabels)
class_labels = ["Clase 0", "Clase 1", "Clase 1", "Clase 2", "Clase 3", "Clase 4", "Clase 5", "Clase 6", "Clase 7", "Clase 8", "Clase 9"]
plt.figure(figsize=(8, 6))
accutxt=f'accuracy: {accuracy*100:.2f}%,'
sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicción')
plt.ylabel('Etiqueta Real')
plt.title('Matriz de Confusión '+ accutxt)
plt.show()
with torch.no_grad():
  for i, data in enumerate(dataloader_val, 0):
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    outputs = model4(inputs)
    _, predicted = torch.max(outputs, 1)
    truelabels.extend(labels.cpu().numpy())
    prediclabels.extend(predicted.cpu().numpy())
cm = confusion_matrix(truelabels, prediclabels, normalize='true')
accuracy=accuracy_score(truelabels, prediclabels)
class_labels = ["Clase 0", "Clase 1", "Clase 1", "Clase 2", "Clase 3", "Clase 4", "Clase 5", "Clase 6", "Clase 7", "Clase 8", "Clase 9"]
plt.figure(figsize=(8, 6))
accutxt=f'accuracy: {accuracy*100:.2f}%,'
sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicción')
plt.ylabel('Etiqueta Real')
plt.title('Matriz de Confusión '+ accutxt)
plt.show()

# Graficar loss de entrenamiento Y validación
plt.figure(figsize = (8, 5))
plt.title('pérdida en entrenamiento y validación')
plt.xlabel('Épocas')
plt.ylabel('Pérdida')
plt.plot(epocas, loss_train, 'b', label = 'Entrenamiento')
plt.plot(epocas, loss_val, 'r', label = 'Validación')
plt.grid()
plt.legend()

"""(e) 2 capas ocultas con 10 y 10 neuronas cada una y función de activación ReLU, y 1000 épocas
como máximo.
"""

model5 = nn.Sequential(
          nn.Linear(64, 10),
          nn.ReLU(),
          nn.Linear(10,10),
          nn.ReLU(),
          nn.Linear(10,10)
        )

device = torch.device('cuda')

model5 = model5.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model5.parameters(), lr=1e-3)

start = time.time()

loss_train= []
loss_val= []
accuracy_t = [] #guarda accuracy en cada batch, en el entrenamiento
accuracy_v = []
epocas = []
cont = 0
paciencia = 4
truelabels = []
prediclabels = []
# loop over the dataset multiple times
for epoch in range(1000):
  # Guardar loss de cada batch
  loss_train_batches = [] # guarda pérdidas de cada batch en el entrenamiento
  loss_val_batches = []
  model5.train()
  correct = 0
  total = 0
  total1 = 0
  correct1 = 0

  # Train on the current epoch
  for i, data in enumerate(dataloader_train, 0):
    # Process the current batch
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    # zero the parameter gradients
    optimizer.zero_grad()
    # forward + backward + optimize
    outputs = model5(inputs)
    loss = criterion(outputs, labels)
    loss.backward() # backpropagation
    optimizer.step()

    # Por completar: calcule la pérdida de entrenamiento y acurracy en el batch actual
    loss_train_batches.append(loss.item())

##-----------Accuracy en la época actual--------------------------------------
    _, predicted = torch.max(outputs, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
  accuracy = correct / total
  accuracy_t.append(accuracy)
  ##-----------------------------------------------------------------------------------------

  # Pérdida de entrenamiento y accuracy en la época actual
  loss_train.append(np.mean(loss_train_batches)) #***loss promedio en cada época***

###--------------------***Predicción en el conjunto de validación***------------------
  model5.eval()


  with torch.no_grad():
    # Por completar: calcule la pérdida de validación y acurracy en la época actual
    for i, data in enumerate(dataloader_val, 0):
      # Procesar batch actual
      inputs = data["features"].to(device) # Características
      labels = data["labels"].to(device)   # Clases

      outputs = model5(inputs)              # Obtenemos predicciones

      # Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      loss_val_batches.append(loss.item())
##-----------Accuracy en la época actual--------------------------------------
      _, predicted = torch.max(outputs, 1)
      total1 += labels.size(0)
      correct1 += (predicted == labels).sum().item()
  accuracy = correct1 / total1
  accuracy_v.append(accuracy)
##-------------------------------------------------------------------------------------------

  # Guardamos el Loss de validación de la época actual
  loss_val.append(np.mean(loss_val_batches)) # Loss promedio de los batches
  epocas.append(epoch)
  if len(loss_val)>1:
    dif=loss_val[-1]-loss_val[-2]
    if dif >= 0:
      cont+=1
      if cont >= paciencia:
        break


  # Por hacer: imprima la pérdida de entrenamiento/validación y acurracy en la época actual
  print('epoch: %d, mean train loss: %.4f, mean val loss: %.4f, accuracy train: %.4f, accuracy val: %f' %((epoch), loss_train[epoch], loss_val[epoch], accuracy_t[epoch], accuracy_v[epoch] ))


# Crea un mapa de calor de la matriz de confusión-------------------------------------------
last.append(accuracy_v[epoch-1])
end = time.time()

print('Finished Training, total time %f seconds' % (end - start))

#----------------Matriz de confusión---------------------------
model5.eval()
with torch.no_grad():
  for i, data in enumerate(dataloader_train, 0):
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    outputs = model5(inputs)
    _, predicted = torch.max(outputs, 1)
    truelabels.extend(labels.cpu().numpy())
    prediclabels.extend(predicted.cpu().numpy())
cm = confusion_matrix(truelabels, prediclabels, normalize='true')
accuracy=accuracy_score(truelabels, prediclabels)
class_labels = ["Clase 0", "Clase 1", "Clase 1", "Clase 2", "Clase 3", "Clase 4", "Clase 5", "Clase 6", "Clase 7", "Clase 8", "Clase 9"]
plt.figure(figsize=(8, 6))
accutxt=f'accuracy: {accuracy*100:.2f}%,'
sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicción')
plt.ylabel('Etiqueta Real')
plt.title('Matriz de Confusión '+ accutxt)
plt.show()
with torch.no_grad():
  for i, data in enumerate(dataloader_val, 0):
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    outputs = model5(inputs)
    _, predicted = torch.max(outputs, 1)
    truelabels.extend(labels.cpu().numpy())
    prediclabels.extend(predicted.cpu().numpy())
cm = confusion_matrix(truelabels, prediclabels, normalize='true')
accuracy=accuracy_score(truelabels, prediclabels)
class_labels = ["Clase 0", "Clase 1", "Clase 1", "Clase 2", "Clase 3", "Clase 4", "Clase 5", "Clase 6", "Clase 7", "Clase 8", "Clase 9"]
plt.figure(figsize=(8, 6))
accutxt=f'accuracy: {accuracy*100:.2f}%,'
sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicción')
plt.ylabel('Etiqueta Real')
plt.title('Matriz de Confusión '+ accutxt)
plt.show()

# Graficar loss de entrenamiento Y validación
plt.figure(figsize = (8, 5))
plt.title('pérdida en entrenamiento y validación')
plt.xlabel('Épocas')
plt.ylabel('Pérdida')
plt.plot(epocas, loss_train, 'b', label = 'Entrenamiento')
plt.plot(epocas, loss_val, 'r', label = 'Validación')
plt.grid()
plt.legend()

"""(f) 2 capas ocultas con 40 y 40 neuronas cada una y función de activación ReLU, y 1000 épocas
como máximo.
"""

model6 = nn.Sequential(
          nn.Linear(64, 40),
          nn.ReLU(),
          nn.Linear(40,40),
          nn.ReLU(),
          nn.Linear(40,10)
        )

device = torch.device('cuda')

model6 = model6.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model6.parameters(), lr=1e-3)

start = time.time()

loss_train= []
loss_val= []
accuracy_t = [] #guarda accuracy en cada batch, en el entrenamiento
accuracy_v = []
epocas = []
cont = 0
paciencia = 5
truelabels = []
prediclabels = []
# loop over the dataset multiple times
for epoch in range(1000):
  # Guardar loss de cada batch
  loss_train_batches = [] # guarda pérdidas de cada batch en el entrenamiento
  loss_val_batches = []
  model6.train()
  correct = 0
  total = 0
  total1 = 0
  correct1 = 0

  # Train on the current epoch
  for i, data in enumerate(dataloader_train, 0):
    # Process the current batch
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    # zero the parameter gradients
    optimizer.zero_grad()
    # forward + backward + optimize
    outputs = model6(inputs)
    loss = criterion(outputs, labels)
    loss.backward() # backpropagation
    optimizer.step()

    # Por completar: calcule la pérdida de entrenamiento y acurracy en el batch actual
    loss_train_batches.append(loss.item())

##-----------Accuracy en la época actual--------------------------------------
    _, predicted = torch.max(outputs, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
  accuracy = correct / total
  accuracy_t.append(accuracy)
  ##-----------------------------------------------------------------------------------------

  # Pérdida de entrenamiento y accuracy en la época actual
  loss_train.append(np.mean(loss_train_batches)) #***loss promedio en cada época***

###--------------------***Predicción en el conjunto de validación***------------------
  model6.eval()


  with torch.no_grad():
    # Por completar: calcule la pérdida de validación y acurracy en la época actual
    for i, data in enumerate(dataloader_val, 0):
      # Procesar batch actual
      inputs = data["features"].to(device) # Características
      labels = data["labels"].to(device)   # Clases

      outputs = model6(inputs)              # Obtenemos predicciones

      # Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      loss_val_batches.append(loss.item())
##-----------Accuracy en la época actual--------------------------------------
      _, predicted = torch.max(outputs, 1)
      total1 += labels.size(0)
      correct1 += (predicted == labels).sum().item()
  accuracy = correct1 / total1
  accuracy_v.append(accuracy)
##-------------------------------------------------------------------------------------------

  # Guardamos el Loss de validación de la época actual
  loss_val.append(np.mean(loss_val_batches)) # Loss promedio de los batches
  epocas.append(epoch)
  if len(loss_val)>1:
    dif=loss_val[-1]-loss_val[-2]
    if dif >= 0:
      cont+=1
      if cont >= paciencia:
        break


  # Por hacer: imprima la pérdida de entrenamiento/validación y acurracy en la época actual
  print('epoch: %d, mean train loss: %.4f, mean val loss: %.4f, accuracy train: %.4f, accuracy val: %f' %((epoch), loss_train[epoch], loss_val[epoch], accuracy_t[epoch], accuracy_v[epoch] ))


# Crea un mapa de calor de la matriz de confusión-------------------------------------------
last.append(accuracy_v[epoch-1])
end = time.time()

print('Finished Training, total time %f seconds' % (end - start))

#----------------Matriz de confusión---------------------------
model6.eval()
with torch.no_grad():
  for i, data in enumerate(dataloader_train, 0):
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    outputs = model6(inputs)
    _, predicted = torch.max(outputs, 1)
    truelabels.extend(labels.cpu().numpy())
    prediclabels.extend(predicted.cpu().numpy())
cm = confusion_matrix(truelabels, prediclabels, normalize='true')
accuracy=accuracy_score(truelabels, prediclabels)
class_labels = ["Clase 0", "Clase 1", "Clase 1", "Clase 2", "Clase 3", "Clase 4", "Clase 5", "Clase 6", "Clase 7", "Clase 8", "Clase 9"]
plt.figure(figsize=(8, 6))
accutxt=f'accuracy: {accuracy*100:.2f}%,'
sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicción')
plt.ylabel('Etiqueta Real')
plt.title('Matriz de Confusión '+ accutxt)
plt.show()
with torch.no_grad():
  for i, data in enumerate(dataloader_val, 0):
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    outputs = model6(inputs)
    _, predicted = torch.max(outputs, 1)
    truelabels.extend(labels.cpu().numpy())
    prediclabels.extend(predicted.cpu().numpy())
cm = confusion_matrix(truelabels, prediclabels, normalize='true')
accuracy=accuracy_score(truelabels, prediclabels)
class_labels = ["Clase 0", "Clase 1", "Clase 1", "Clase 2", "Clase 3", "Clase 4", "Clase 5", "Clase 6", "Clase 7", "Clase 8", "Clase 9"]
plt.figure(figsize=(8, 6))
accutxt=f'accuracy: {accuracy*100:.2f}%,'
sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicción')
plt.ylabel('Etiqueta Real')
plt.title('Matriz de Confusión '+ accutxt)
plt.show()

# Graficar loss de entrenamiento Y validación
plt.figure(figsize = (8, 5))
plt.title('pérdida en entrenamiento y validación')
plt.xlabel('Épocas')
plt.ylabel('Pérdida')
plt.plot(epocas, loss_train, 'b', label = 'Entrenamiento')
plt.plot(epocas, loss_val, 'r', label = 'Validación')
plt.grid()
plt.legend()

"""**3**) Usando la mejor red encontrada en validación (aquella con mayor accuracy en validación), calcular
la matriz de confusión normalizada y el accuracy normalizado, usando el conjunto de prueba.

"""

modelos = [model1,model2,model3,model4,model5,model6]

max=max(last) #máximo accuracy final
last.index(max) #posición del máximo accuracy

model=modelos[last.index(max)]

device = torch.device('cuda')

model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
print(last)

#----------------Matriz de confusión---------------------------
model.eval()
with torch.no_grad():
  for i, data in enumerate(dataloader_test, 0):
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    outputs = model(inputs)
    _, predicted = torch.max(outputs, 1)
    truelabels.extend(labels.cpu().numpy())
    prediclabels.extend(predicted.cpu().numpy())
cm = confusion_matrix(truelabels, prediclabels, normalize='true')
accuracy=accuracy_score(truelabels, prediclabels)
class_labels = ["Clase 0", "Clase 1", "Clase 1", "Clase 2", "Clase 3", "Clase 4", "Clase 5", "Clase 6", "Clase 7", "Clase 8", "Clase 9"]
plt.figure(figsize=(8, 6))
accutxt=f'accuracy: {accuracy*100:.2f}%,'
sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicción')
plt.ylabel('Etiqueta Real')
plt.title('Matriz de Confusión '+ accutxt)
plt.show()
with torch.no_grad():
  for i, data in enumerate(dataloader_val, 0):
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    outputs = model(inputs)
    _, predicted = torch.max(outputs, 1)
    truelabels.extend(labels.cpu().numpy())
    prediclabels.extend(predicted.cpu().numpy())
cm = confusion_matrix(truelabels, prediclabels, normalize='true')
accuracy=accuracy_score(truelabels, prediclabels)
class_labels = ["Clase 0", "Clase 1", "Clase 1", "Clase 2", "Clase 3", "Clase 4", "Clase 5", "Clase 6", "Clase 7", "Clase 8", "Clase 9"]
plt.figure(figsize=(8, 6))
accutxt=f'accuracy: {accuracy*100:.2f}%,'
sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicción')
plt.ylabel('Etiqueta Real')
plt.title('Matriz de Confusión '+ accutxt)
plt.show()